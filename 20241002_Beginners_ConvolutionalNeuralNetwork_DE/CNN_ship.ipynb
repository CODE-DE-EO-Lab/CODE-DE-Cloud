{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec8d8d-e25e-467d-bdcf-4dcfe3805f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python\n",
    "#  Schiff Klassifikation mit Satelliten Daten von Kaggle\n",
    "#\n",
    "# Programmstruktur:\n",
    "# 1. Laden der Daten\n",
    "#                 \n",
    "# 2. Organisation der Daten \n",
    "#                \n",
    "# 3. Modellierung\n",
    "#                 \n",
    "#                 Preparing of Test and Train Data</li>\n",
    "#                 Implementation of Artificial Neural Network (ANN)</li>\n",
    "#                 Implementation of Convolutional Neural Network (CNN)</li>  \n",
    "#                 < \n",
    "# \n",
    "#  Daten Informationen\n",
    "# \n",
    "# Planet Daten über der San Francisco Bay von Kaggle: https://www.kaggle.com/datasets/rhammell/ships-in-satellite-imagery\n",
    "#    \n",
    "# Der Datensatz liegt auch als JSON-formatierte Textdatei shipsnet.json vor. Das geladene Objekt enthält Daten, Beschriftungen, Szenen-IDs und Standortlisten.\n",
    "\n",
    "# Werte sind 1 oder 0, und representieren die \"Schiff/Ship\" Klassr der \"Kein Schiff/no-ship\".\n",
    "# **scene id**: Die eindeutige Kennung der PlanetScope-Szene, aus der der Bildchip extrahiert wurde. Die Szenen-ID kann mit der Planet-API verwendet werden, um die gesamte Szene zu suchen und herunterzuladen.\n",
    "# **longitude_latitude**: Die Längen- und Breitengradkoordinaten des Bildmittelpunkts, wobei die Werte durch einen einzelnen Unterstrich getrennt sind.\n",
    "\n",
    "# Die Klasse „Schiff“ umfasst 1000 Bilder. Die Bilder dieser Klasse sind  zentriert auf dem Rumpf eines einzelnen Schiffes. Schiffe unterschiedlicher Größe, Ausrichtung und atmosphärischer Aufnahmebedingungen sind enthalten. Beispielbilder aus dieser Klasse werden unten im Skript angezeigt.\n",
    "\n",
    "# Die Klasse „kein Schiff“ umfasst 3000 Bilder. Ein Drittel davon ist eine zufällige Auswahl verschiedener Landbedeckungsmerkmale – Wasser, Vegetation, nackte Erde, Gebäude usw. –, die keinen Teil eines Schiffs enthalten. Das nächste Drittel sind „Teilschiffe“, die nur einen Teil eines Schiffs enthalten, aber nicht genug, um die vollständige Definition der Klasse „Schiff“ zu erfüllen. Das letzte Drittel sind Bilder, die zuvor von maschinellen Lernmodellen falsch beschriftet wurden, was normalerweise an hellen Pixeln oder starken linearen Merkmalen lag. Beispielbilder aus dieser Klasse werden unten im Skript angezeigt.\n",
    "\n",
    "# Zur Installation der Bibliotheken etc siehe auch:\n",
    "# https://www.activestate.com/resources/quick-reads/how-to-install-keras-and-tensorflow/\n",
    "#\n",
    "\n",
    "#!pip install numpy pandas rasterio tensorflow matplotlib scikit-learn scikeras seaborn\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio import plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#1. Laden der Daten\n",
    "# Hier ist ein Besipiel einer Planet Szene..\n",
    "#scene=\"kaggle/input/ships-in-satellite-imagery/scenes/scenes/lb_2.png\"\n",
    "scene=\"lb_2.png\"\n",
    "with rasterio.open(scene) as src:\n",
    "  data=src.read()\n",
    "  plot.show(data, title = \"Planet Szene 2\")\n",
    "\n",
    "#with open('kaggle/input/ships-in-satellite-imagery/shipsnet.json') as data_file:\n",
    "with open('../shipsnet.json') as data_file:\n",
    "    dataset = json.load(data_file)\n",
    "shipsnet= pd.DataFrame(dataset)\n",
    "shipsnet.head()\n",
    "\n",
    "\n",
    "#  Wir benötigen nur zwei Spalten: data und labels. \n",
    "\n",
    "shipsnet = shipsnet[[\"data\", \"labels\"]]\n",
    "shipsnet.head()\n",
    "\n",
    "len(shipsnet[\"data\"].iloc[0])\n",
    "\n",
    "\n",
    "# Die Datenwerte von jedem 80x80 RGB Bild sind in einer Liste von 19200 Integer Werten abgelegt. Die ersten 6400 Einträge sind der rote Kanal, die nächten 6400 grün, und 6400 blau.\n",
    "#\n",
    "\n",
    "ship_images = shipsnet[\"labels\"].value_counts()[1]\n",
    "no_ship_images = shipsnet[\"labels\"].value_counts()[0]\n",
    "print(\"Anzahl der Schiff-Bilder:{}\".format(ship_images),\"\\n\")\n",
    "print(\"Anzahl der Kein-Schiff-Bilder:{}\".format(no_ship_images))\n",
    "\n",
    "\n",
    "# 2. Organisation der Daten\n",
    "# Arrays mit x als y Variablen\n",
    "x = np.array(dataset['data']).astype('uint8')\n",
    "y = np.array(dataset['labels']).astype('uint8')\n",
    "\n",
    "x.shape\n",
    "\n",
    "# Die aktuellen Daten für jedes Bild sind eine Reihe von abgeflachten 19.200 Datenpunkten, die die RGB-Werte jedes Pixels darstellen. Wir müssen sie also umformen. Nach der Umformung besteht jedes Element in der neuen x-Variable aus 3 Listen. Jede dieser Listen enthält RGB-Werte für jedes Pixel für die Länge und Breite des Bilds.\n",
    "\n",
    "x_reshaped = x.reshape([-1, 3, 80, 80])\n",
    "x_reshaped.shape\n",
    "\n",
    "\n",
    "# Änderung der Dimensionen\n",
    "x_reshaped = x.reshape([-1, 3, 80, 80]).transpose([0,2,3,1])\n",
    "x_reshaped.shape\n",
    "y.shape\n",
    "\n",
    "#  Die y Variable enthält die Label 1 oder 0. \n",
    "y_reshaped = to_categorical(y, num_classes=2)\n",
    "y_reshaped.shape\n",
    "y_reshaped\n",
    "\n",
    "# Wir sehen uns die Bilder an. \n",
    "image_no_ship = x_reshaped[y==0]\n",
    "image_ship = x_reshaped[y==1]\n",
    "\n",
    "def plot(a,b):\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i, k in enumerate(range(1,9)):\n",
    "        if i < 4:\n",
    "            plt.subplot(2,4,k)\n",
    "            plt.title('Kein Schiff')\n",
    "            plt.imshow(image_no_ship[i+2])\n",
    "            plt.axis(\"off\")\n",
    "        else:\n",
    "            plt.subplot(2,4,k)\n",
    "            plt.title('Schiff')\n",
    "            plt.imshow(image_ship[i+15])\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "    plt.subplots_adjust(bottom=0.3, top=0.7, hspace=0.25)\n",
    "    plt.show()\n",
    "\n",
    "# Anwendung der Funktion \n",
    "plot(image_no_ship, image_ship)\n",
    "\n",
    "\n",
    "# 3. Modelling \n",
    "# Normalisierung der X-Daten \n",
    "\n",
    "x_reshaped = x_reshaped / 255\n",
    "#x_reshaped[0][0][0] # Normalisierte RGB Werte des ersten Pixel des ersten Bildes\n",
    "\n",
    "\n",
    "# Aufteilung der Daten in Training- und Test-Daten.\n",
    "x_train_1, x_test, y_train_1, y_test = train_test_split(x_reshaped, y_reshaped,\n",
    "                                                        test_size = 0.20, random_state = 42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_1, y_train_1, \n",
    "                                                  test_size = 0.25, random_state = 42)\n",
    "\n",
    "print(\"x_train shape\",x_train.shape)\n",
    "print(\"x_test shape\",x_test.shape)\n",
    "print(\"y_train shape\",y_train.shape)\n",
    "print(\"y_test shape\",y_test.shape)\n",
    "print(\"y_train shape\",x_val.shape)\n",
    "print(\"y_test shape\",y_val.shape)\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "\n",
    "# Implementation des Convolutional Neural Network (CNN)\n",
    "\n",
    "from keras import callbacks\n",
    "model = Sequential()\n",
    "#\n",
    "model.add(Conv2D(filters = 64, kernel_size = (4,4),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (80,80,3)))\n",
    "model.add(MaxPool2D(pool_size=(5,5)))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(1,1)))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "model.add(Conv2D(filters = 16, kernel_size = (2,2),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(1,1)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "#optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 10, \n",
    "                                        restore_best_weights = True)\n",
    "history = model.fit(x_train, y_train, epochs = 20, validation_data=(x_val, y_val), callbacks = [earlystopping])\n",
    "\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).plot();\n",
    "\n",
    "\n",
    "#  Daten Augmentation \n",
    "# Daten Augmentation ist eine Strategie der Datenerweiterung, die es ermöglicht die Vielfalt der für Trainingsmodelle verfügbaren Daten erheblich zu erhöhen, ohne neue Daten zu sammeln. Datenerweiterungstechniken wie Zuschneiden, Auffüllen und horizontales Spiegeln werden üblicherweise zum Trainieren großer neuronaler Netze verwendet.\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False, \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,\n",
    "        rotation_range=5,  \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False, \n",
    "        vertical_flip=False)  \n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "# Eine kleine Augmentation auf ein Bild anwenden:\n",
    "\n",
    "data = x_reshaped[y==1][15]\n",
    "# Dimension auf eine Datenprobe erweitern\n",
    "samples = expand_dims(data, 0)\n",
    "# Bild data augmentation generator\n",
    "datag = ImageDataGenerator(brightness_range=[0.2,1.0],\n",
    "                          zoom_range=[0.5,1.0],\n",
    "                          horizontal_flip=True,\n",
    "                          rotation_range=90)\n",
    "# prepare iterator\n",
    "it = datag.flow(samples, batch_size=1)\n",
    "# Generiere Daten und Plotte\n",
    "plt.figure(figsize = (10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "#    batch = it.next()\n",
    "    batch = next(it)\n",
    "    # Konvertierung zu Integer\n",
    "    image = batch[0].astype('uint8')\n",
    "    plt.imshow(image)  \n",
    "plt.show()\n",
    "\n",
    "# Daten Augmentation für die training Daten und erneuter fit.\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train), epochs = 20, \n",
    "                    validation_data=(x_val, y_val), callbacks = [earlystopping])\n",
    "\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "Y_pred = model.predict(x_test)\n",
    "\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "# Konfusionsmatrix\n",
    "\n",
    "print(\"\\n\"\"Test Accuracy Score : \",metrics.accuracy_score(Y_true, Y_pred_classes),\"\\n\")\n",
    "\n",
    "fig, axis = plt.subplots(1, 3, figsize=(20,6))\n",
    "axis[0].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axis[0].set_title(\"Validation Accuracy\")\n",
    "axis[0].set_xlabel(\"Epochs\")\n",
    "axis[0].set_ylabel(\"Val. Acc.\")\n",
    "axis[1].plot(history.history['accuracy'], label='acc')\n",
    "axis[1].set_title(\"Training Accuracy\")\n",
    "axis[1].set_xlabel(\"Epochs\")\n",
    "axis[0].set_ylabel(\"Train. Acc.\")\n",
    "axis[2].plot(history.history['val_loss'], label='val_loss')\n",
    "axis[2].set_title(\"Test Loss\")\n",
    "axis[2].set_xlabel(\"Epochs\")\n",
    "axis[2].set_ylabel(\"Loss\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# Plot der Konfusionsmatrix\n",
    "f,ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(history.history).plot();\n",
    "\n",
    "# Vorhersage der test Data mit dem CNN. Erstes Bild der Test daten\n",
    "\n",
    "prediction = model.predict(x_test)\n",
    "pd.Series(prediction[0], index=[\"Not A Ship\", \"Ship\"])\n",
    "\n",
    "# Die Geauigkeiten sind gegenüber dem ANN verbesert!\n",
    "# Schauen wir uns die Bilder einmal an\n",
    "\n",
    "\n",
    "predicted_data = pd.DataFrame(prediction, columns=[\"Not a Ship\", \"Ship\"])\n",
    "predicted_data.head(3)\n",
    "\n",
    "y_test_data = pd.DataFrame(y_test, columns=[\"Not a Ship\", \"Ship\"])\n",
    "y_test_data.head(3)\n",
    "\n",
    "predicted_data['There is a Ship'] = y_test[:, 1]\n",
    "predicted_data.head()\n",
    "\n",
    "predicted_data[\"Difference\"] = predicted_data[\"Ship\"] - predicted_data[\"There is a Ship\"]\n",
    "predicted_data\n",
    "\n",
    "\n",
    "# Wenn der Unterschied (Difference) groß ist, bedeutet dies, dass das Bild als Schiff vorhergesagt wurde, obwohl es sich nicht um ein Schiff handelte. Um solche vorhergesagten Bilder zu sehen, müssen wir die Differenzspalte vom größten zum kleinsten sortieren.\n",
    "\n",
    "\n",
    "predicted_data.sort_values('Difference', ascending=False).head(10)\n",
    "\n",
    "indexes = predicted_data.sort_values('Difference', ascending = False).head(4).index.to_list()\n",
    "\n",
    "def plotHistogram(image_index):\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(x_test[image_index])\n",
    "    plt.axis('off')\n",
    "    plt.title('Kein Schiff, aber vorhergesagt als Schiff.')\n",
    "    histo = plt.subplot(2,2,2)\n",
    "    histo.set_ylabel('Count', fontweight = \"bold\")\n",
    "    histo.set_xlabel('Pixel Intensity', fontweight = \"bold\")\n",
    "    n_bins = 30\n",
    "    plt.hist(x_test[image_index][:,:,0].flatten(), bins = n_bins, lw = 0, color = 'r', alpha = 0.5);\n",
    "    plt.hist(x_test[image_index][:,:,1].flatten(), bins = n_bins, lw = 0, color = 'g', alpha = 0.5);\n",
    "    plt.hist(x_test[image_index][:,:,2].flatten(), bins = n_bins, lw = 0, color = 'b', alpha = 0.5);\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Implementation der Funktion\n",
    "for i in indexes:\n",
    "    plotHistogram(i)\n",
    "\n",
    "# Die CNN Genauigkeiten sind höher als beim ANN!\n",
    "#end of CNN code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42076c0-9930-453a-8651-ab24ddaf3098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
